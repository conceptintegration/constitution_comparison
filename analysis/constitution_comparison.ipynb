{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Constitutions\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook presents a semantic similarity analysis of Chilean constitutional texts and related Latin American constitutions. We employ two complementary approaches to understand the relationships between constitutional documents: \n",
    "1. Textual alignment of constitutions using Kernel Density Estimation (KDE).\n",
    "2. Thematic alignment of constitutions by comparing the distributions of topic mentions.\n",
    "\n",
    "Both methods are based on semantic embeddings and textual analysis, but they measure different aspects of constitutional relationships. \n",
    "\n",
    "Textual alignment measures direct semantic relationships between individual constitution text segments in order to compare the similarity of language and phrasing between two constitutions. This creates a composite signal containing both linguistic and thematic dimensions—high semantic similarity without thematic overlap is impossible because topics are expressed by segments.\n",
    "\n",
    "In contrast, the topic alignment method isolates the thematic dimension to reveal which topics are prioritised by creating a topic profile for each constitution. This profile is created by measuring the semantic similarity between pre-defined topics belonging to the CCP ontology and constitution text segments.\n",
    "\n",
    "The relationship between segment-segment (textual alignment) and topic-segment (thematic alignment) similarity reveals important patterns:\n",
    "\n",
    "1. High thematic alignment + moderate textual alignment: Two constitutions prioritise the same topics but express these topics in different language. The topic method reveals underlying structural similarity that segment-level comparison underestimates due to linguistic variation. This pattern indicates conceptual convergence—drafters adopted similar thematic frameworks but crafted original constitutional language.\n",
    "2. Moderate textual similarity + lower thematic similarity: The constitutions share some constitutional vocabulary and formulaic language but differ in their substantive topic priorities. Constitutional boilerplate creates segment-level similarity even when thematic emphasis diverges. The topic alignment method filters out this noise to reveal the true differences between constitution priorities.\n",
    "3. Both high: Strong alignment on both dimensions—constitutions share thematic priorities and express them in similar language (genuine textual borrowing with topic overlap).\n",
    "4. Both low: Fundamentally different constitutions with neither thematic nor linguistic commonality.\n",
    "\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "The analysis examines four Chilean constitutions:\n",
    "\n",
    "- The 1980 constitution (as amended through 2021).\n",
    "- The rejected 2018 reform proposal.\n",
    "- The rejected 2022 progressive draft\n",
    "- The rejected 2023 conservative draft.\n",
    "\n",
    "The Chilean constitutions offer a unique opportunity to study constitutional evolution, reform failure, and the dynamics of constitutional change.\n",
    "\n",
    "In addition there are two comparative cases representing the new Latin American constitutionalism movement:\n",
    "\n",
    "- Ecuador's 2008 constitution.\n",
    "- Bolivia's 2009 Constitution.\n",
    "\n",
    "Constitution labels in constitution enacted or draft date order used in the notebook are:\n",
    "\n",
    "- Chile_2021—1980\n",
    "- Ecuador_2021—2008\n",
    "- Bolivia_2009—2009\n",
    "- Chile_2018D—2018\n",
    "- Chile_2022D—2022\n",
    "- Chile_2023DD—2023\n",
    "\n",
    "\n",
    "## Method 1: Textual Alignment of Constitutions\n",
    "\n",
    "### Overview\n",
    "\n",
    "For each pair of constitutions, we construct a similarity matrix where rows represent segments from one constitution (A) and columns represent segments from the other constitution (B). From this matrix, we extract bidirectional maximum similarities: for each segment in Constitution A, we identify its most similar segment in Constitution B, and vice versa. This provides a semantic similarity distribution for a pair of constitutions.\n",
    "\n",
    "We apply kernel density estimation (KDE) to our observed text segment semantic similarity distributions. KDE is a non-parametric method used to estimate the probability density function (PDF) of observed data (Silverman, B.W., 1986. Density Estimation for Statistics and Data Analysis, Chapman and Hall, London.). \n",
    "\n",
    "KDE offers several advantages:\n",
    "\n",
    "- Distribution-agnostic: We estimate the shape of underlying similarity distributions without assuming they follow known parametric forms (e.g., normal, uniform)\n",
    "- Sample size control: KDE enables fair comparison between pairs of constitutions of different length. A short constitution with consistently high matches can be properly compared to a much longer one.\n",
    "- Mathematical operations: We can integrate under the right tail to quantify the proportion of high-quality matches.\n",
    "- Visual interpretability: KDE curves reveal structural features like bimodality, which might indicate mixed drafting strategies (e.g., extensive borrowing for some provisions, genuine innovation for others).\n",
    "\n",
    "### The Semantic Alignment Metric\n",
    "\n",
    "Using integration, we determine the area under a PDF $p$ within a similarity score interval $I$ with limits $[a,1.0]$. The area $p$ is the probability that a similarity score $x$ is in the interval and is our measure of textual semantic alignment $A$.\n",
    "\n",
    "$$A = \\Pr(x \\in I) = \\int_{a}^{1.0} p(x) \\, dx$$\n",
    "\n",
    "Our approach captures the probability mass in the high-similarity region, representing the extent to which two constitutions share closely aligned language. Higher integral values indicate greater constitutional similarity.\n",
    "\n",
    "### Interpreting Bimodality\n",
    "\n",
    "When KDE reveals bimodal distributions a peak at high similarity may indicate extensive textual borrowing or minimal modification. Bimodality may therefore indicate a conservative drafting strategy—preserving some provisions while reforming others—revealing political compromises and/or evolutionary reform approaches.\n",
    "\n",
    "\n",
    "## Method 2: Thematic Alignment of Constitutions\n",
    "\n",
    "### Overview\n",
    "\n",
    "The thematic alignment method measures constitutional similarity based on topics in constitutions rather than textual content. The topic profile of a constitution reveals which topics a constitution prioritises and is used to compare constitutions.\n",
    "\n",
    "For each constitution we create a topic-segment matrix $c$ containing the semantic similarities of all topic-segment pairs. For each segment $j$ in $c$, we identify the $k$ topics with highest similarity scores and set all other topics scores to zero:\n",
    "\n",
    "$$T^{(k)}_c[i,j] = \\begin{cases} \n",
    "T_c[i,j] & \\text{if topic } i \\text{ is in top-}k \\text{ for segment } j \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "Where:\n",
    "- $T_c$ is the topic-segment similarity matrix for constitution $c$ (topics × segments)\n",
    "- $i$ indexes topics, $j$ indexes segments\n",
    "- $k$ is the number of top topics to retain (e.g., $k=3$)\n",
    "\n",
    "By retaining only the strongest topic associations for a segment we prevent weak associations from homogenising a constitution's topic profile.\n",
    "\n",
    "Next, a constitution's topic profile is computed as the topic marginal of the filtered topic-segment matrix. For each topic $i$ in constitution $c$, we compute the marginal by summing across all segments and normalising by the number of segments:\n",
    "\n",
    "$$\\hat{M}_c[i] = \\frac{1}{n_c} \\sum_{j=1}^{n_c} T^{(k)}_c[i,j]$$\n",
    "\n",
    "Where:\n",
    "- $n_c$ is the number of segments in constitution $c$\n",
    "- $\\hat{M}_c[i]$ represents the average emphasis on topic $i$ per segment\n",
    "\n",
    "\n",
    "### The Thematic Alignment Metric\n",
    "\n",
    "For any pair of constitutions $(c_1, c_2)$, we compute their topic alignment using vector similarity metrics.\n",
    "\n",
    "Topics with non-zero coverage in at least one constitution are identified to create a mask:\n",
    "\n",
    "$$\\text{mask}[i] = (\\hat{M}_{c_1}[i] > 0) \\lor (\\hat{M}_{c_2}[i] > 0)$$\n",
    "\n",
    "This removes topics that neither constitution emphasises, focusing the comparison on relevant topics only.\n",
    "\n",
    "For constitution pair $(c_1, c_2)$, we compute similarity between masked topics profiles:\n",
    "\n",
    "**Pearson Correlation:**\n",
    "\n",
    "$$r(c_1, c_2) = \\frac{\\sum_{i \\in \\text{mask}} (\\hat{M}_{c_1}[i] - \\bar{M}_{c_1})(\\hat{M}_{c_2}[i] - \\bar{M}_{c_2})}{\\sqrt{\\sum_{i \\in \\text{mask}} (\\hat{M}_{c_1}[i] - \\bar{M}_{c_1})^2} \\sqrt{\\sum_{i \\in \\text{mask}} (\\hat{M}_{c_2}[i] - \\bar{M}_{c_2})^2}}$$\n",
    "\n",
    "Where $\\bar{M}_c$ is the mean of the masked marginals for constitution $c$.\n",
    "\n",
    "**Cosine Similarity:**\n",
    "\n",
    "$$\\text{sim}(c_1, c_2) = \\frac{\\sum_{i \\in \\text{mask}} \\hat{M}_{c_1}[i] \\times \\hat{M}_{c_2}[i]}{\\sqrt{\\sum_{i \\in \\text{mask}} \\hat{M}_{c_1}[i]^2} \\times \\sqrt{\\sum_{i \\in \\text{mask}} \\hat{M}_{c_2}[i]^2}}$$\n",
    "\n",
    "**Output**: A single similarity value in $[0, 1]$ (for cosine) or $[-1, 1]$ (for correlation) indicating topic alignment between the two constitutions.\n",
    "\n",
    "## Summary\n",
    "\n",
    "KDE analysis provides robust, distribution-aware similarity metrics for ranking constitution pairs. Topic profile analysis explains the substantive basis of those similarities, revealing whether constitutions align on core principles, procedural structures, or specific policy domains.\n",
    "\n",
    "Together, they offer both quantitative rigour (through mathematical integration and statistical density estimation) and qualitative insight (through topic-level interpretation), making constitutional comparison both systematic and meaningful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise\n",
    "\n",
    "This cell loads Python packages and functions. It also loads the data model created by the code in the `processing` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__      = 'Roy Gardner'\n",
    "__copyright__   = 'Copyright 2023-2025, Roy and Sally Gardner'\n",
    "\n",
    "%run ./_library/packages.py\n",
    "%run ./_library/utilities.py\n",
    "%run ./_library/mapping.py\n",
    "%run ./_library/kde_pdf.py\n",
    "\n",
    "model_path = '../model/'\n",
    "\n",
    "try:\n",
    "    n = len(model_dict)\n",
    "except:\n",
    "    exclusion_list=['segment_encoding.json','topic_encodings.json']\n",
    "    model_dict = do_load(model_path,exclusion_list=[],verbose=True)\n",
    "\n",
    "\n",
    "# Get the ojects we need for the analysis from the data model\n",
    "documents_dict = model_dict['documents_dict']\n",
    "segments_dict = model_dict['segments_dict']\n",
    "encoded = model_dict['encoded_segments']\n",
    "segments_matrix = np.array(model_dict['segments_matrix'])\n",
    "topic_segment_matrix = np.array(model_dict['topic_segment_matrix'])\n",
    "\n",
    "# Create some constitution labels for visualisations\n",
    "doc_data = [(k,v['date']) for k,v in documents_dict.items()]\n",
    "doc_data = sorted(doc_data,key=lambda t:t[1])\n",
    "const_list = []\n",
    "for doc in doc_data:\n",
    "    const_list.append(f'{doc[0]}—{doc[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual Alignment\n",
    "\n",
    "### Method\n",
    "\n",
    "The method processes the matrix `segments_matrix` contained in `model_dict`. This matrix contains the semantic similarities of all pairs of segments in our set of constitutions. \n",
    "\n",
    "For each constitution pairing:\n",
    "\n",
    "- Collect the **row** indices from the `segments_matrix` correponding to the first constitution's sections.\n",
    "- Collect the **column** indices from the `segments_matrix` correponding to the second constitution's sections.\n",
    "- Use the row and column indices to extract a sub-matrix from the `segments_matrix`.\n",
    "- Extract the bidirectional maximum similarity values from the sub-matrix. The rationale is that a row segment $s_i$ may be maximally similar to a column segment $s_j$, but $s_j$ might not be maximally similar to $s_i$.\n",
    "- Use the maximum similarity values to generate a probability density function (PDF) using Kernel Density Estimation (KDE). Rationale: The more similar a pair of constitutions the longer and denser the right-hand tail of the distribution. \n",
    "- Integrate under the PDF in a given similarity score interval (default 0.7 - 1.0) to measure the likelihood that a pair of constitutions contain semantically similar sections.\n",
    "- Visualise the PDFs and the integral values.\n",
    "\n",
    "### Visualisations\n",
    "\n",
    "Three visualisations are presented:\n",
    "\n",
    "- PDFs for each pair of constitutions.\n",
    "- A bar chart for comparisng the relative values of integral values over pairs of constitutions.\n",
    "- A heatmap showing integrals values for each every of constitutions.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "#### Conservative Chilean constitutions\n",
    "\n",
    "At the integral limits used in the analysis, the similarity of three Chilean constitutions is striking. These constitutions are:\n",
    "- The in-force constitution `Chile_2021` enacted in 1980.\n",
    "- The draft constitution `Chile_2018D`.\n",
    "- The draft constitution `Chile_2023DD`.\n",
    "\n",
    "All three pairwise comparisons of these constitutions:\n",
    "\n",
    "- `Chile_2021—Chile_2018D`\n",
    "- `Chile_2021—Chile_2023DD`\n",
    "- `Chile_2018D—Chile_2023DD`\n",
    "\n",
    "show:\n",
    "\n",
    "- Long right-hand tails in the PDF with varying degrees of bimodality. The pair `Chile_2021—Chile_2018D` has two clear peaks in the distribution.\n",
    "- Their integral values are the three largest values as shown in the bar chart and the heatmap.\n",
    "\n",
    "#### Ecuador and Bolivia\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "samples_list = [] # samples for KDE\n",
    "labels_list = [] # Labels for constitution pairs\n",
    "matrix_dict = {} # Store the matrices for the constitution pairs\n",
    "\n",
    "# Get pairwise combinations of constitutions\n",
    "combs = list(combinations(doc_data,r=2))\n",
    "for c in combs:\n",
    "    row_doc = c[0][0]\n",
    "    col_doc = c[1][0]\n",
    "    # Get row segment IDs\n",
    "    row_segment_ids = [k for k,_ in segments_dict.items() if k.split('/')[0] == row_doc and\\\n",
    "                             k in encoded]\n",
    "    # Translate row segment IDs into row segment indices\n",
    "    row_segment_indices = [encoded.index(segment_id) for segment_id in row_segment_ids]\n",
    "    \n",
    "    # Get column segment IDs\n",
    "    col_segment_ids = [k for k,_ in segments_dict.items() if k.split('/')[0] == col_doc and\\\n",
    "                             k in encoded]\n",
    "    # Translate column segment IDs into column segment indices\n",
    "    col_segment_indices = [encoded.index(segment_id) for segment_id in col_segment_ids]\n",
    "        \n",
    "    # Get the segments sub-matrix for the pair of constitutions\n",
    "    matrix = segments_matrix[np.ix_(row_segment_indices,col_segment_indices)]\n",
    "    # Get the maximum similarity scores for the sub-matrix\n",
    "    samples_list.append(get_max_scores(matrix))\n",
    "    label = f'{c[0][0]}—{c[0][1]} versus {c[1][0]}—{c[1][1]}'\n",
    "    labels_list.append(label)\n",
    "    matrix_dict[(c[0]),c[1]] = matrix\n",
    "    \n",
    "print()\n",
    "\n",
    "# Compute and visualise the PDFs using KDE\n",
    "print('PDFs for pairs of constitutions from the set - see legend.')\n",
    "plot_pdfs(samples_list,labels_list,xlim=[0.5,1.0])\n",
    "\n",
    "# Compute the PDF integrals within the defined limits\n",
    "limits = [0.7,1.0]\n",
    "integrals = get_pdf_integrals(samples_list,limits,sample_size=2)\n",
    "print()\n",
    "\n",
    "# Plot the relative magnitude of the the integrals\n",
    "print('Relative magnitude of integrals in interval for pairs of constitutions.')\n",
    "plot_pdf_integrals(integrals,labels_list,limits,'Similarity of constitution pair','Constitution pair',\\\n",
    "                   title_suffix='',figsize=(8,6))\n",
    "\n",
    "\n",
    "# Plot a heatmap of integral values\n",
    "integral_matrix = np.zeros((len(doc_data),len(doc_data)))\n",
    "for i,c in enumerate(combs):\n",
    "    integral_matrix[doc_data.index(c[0]),doc_data.index(c[1])] = integrals[i]\n",
    "    \n",
    "plt.imshow(integral_matrix,aspect='auto',cmap=mpl.cm.Blues)\n",
    "plt.yticks(range(0,len(const_list)),const_list)\n",
    "plt.xticks(range(0,len(const_list)),const_list,rotation=90)\n",
    "for (j,i),value in np.ndenumerate(integral_matrix):\n",
    "    if round(value,2) > 0.3:\n",
    "        color = 'white'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    if value > 0:\n",
    "        plt.text(i,j,round(value,2),color=color,ha='center',va='center',alpha=0.9)\n",
    "plt.grid(alpha=0.6)\n",
    "plt.title('Heatmap of integral values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment similarity analysis\n",
    "\n",
    "We compare the counts of identical and high-similarity segment in our constitution pairs and present the results in heatmaps. This confirms the finding of the KDE analysis with respect to the three conservative Chilean constitutions.\n",
    "\n",
    "A list of identical segments is also provided for the three conservative Chilean constitutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot a heatmap of identical segments\n",
    "identical_dict = {}\n",
    "identical_matrix = np.zeros((len(doc_data),len(doc_data))).astype(int)\n",
    "for i,c in enumerate(combs):\n",
    "    row_doc = c[0][0]\n",
    "    col_doc = c[1][0]\n",
    "    # Get row segment IDs\n",
    "    row_segment_ids = [k for k,_ in segments_dict.items() if k.split('/')[0] == row_doc and\\\n",
    "                             k in encoded]\n",
    "    # Get column segment IDs\n",
    "    col_segment_ids = [k for k,_ in segments_dict.items() if k.split('/')[0] == col_doc and\\\n",
    "                             k in encoded]\n",
    "    \n",
    "    matrix = matrix_dict[(c[0],c[1])]\n",
    "    indices = np.where(matrix == 1.0)\n",
    "    # Collect the actual segments\n",
    "    row_indices = indices[0]\n",
    "    if len(row_indices) > 0:\n",
    "        col_indices = indices[1]\n",
    "        identical_dict[(c[0],c[1])] =\\\n",
    "         [(row_segment_ids[index],col_segment_ids[col_indices[j]]) for j,index in enumerate(row_indices)]\n",
    "        \n",
    "    identical_matrix[doc_data.index(c[0]),doc_data.index(c[1])] = len(indices[0])\n",
    "    \n",
    "plt.imshow(identical_matrix,aspect='auto',cmap=mpl.cm.Blues)\n",
    "plt.yticks(range(0,len(const_list)),const_list)\n",
    "plt.xticks(range(0,len(const_list)),const_list,rotation=90)\n",
    "for (j,i),value in np.ndenumerate(identical_matrix):\n",
    "    if value > 5:\n",
    "        color = 'white'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    if value > 0:\n",
    "        plt.text(i,j,value,color=color,ha='center',va='center',alpha=0.9)\n",
    "plt.grid(alpha=0.6)\n",
    "plt.title('Heatmap of identical segments')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot a heatmap of high similarity segments\n",
    "identical_matrix = np.zeros((len(doc_data),len(doc_data))).astype(int)\n",
    "for i,c in enumerate(combs):\n",
    "    matrix = matrix_dict[(c[0],c[1])]\n",
    "    indices = np.where(matrix >= 0.8)\n",
    "    identical_matrix[doc_data.index(c[0]),doc_data.index(c[1])] = len(indices[0])\n",
    "    \n",
    "plt.imshow(identical_matrix,aspect='auto',cmap=mpl.cm.Blues)\n",
    "plt.yticks(range(0,len(const_list)),const_list)\n",
    "plt.xticks(range(0,len(const_list)),const_list,rotation=90)\n",
    "for (j,i),value in np.ndenumerate(identical_matrix):\n",
    "    if value > 200:\n",
    "        color = 'white'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    if value > 0:\n",
    "        plt.text(i,j,value,color=color,ha='center',va='center',alpha=0.9)\n",
    "plt.grid(alpha=0.6)\n",
    "plt.title('Heatmap of segments with high semantic similarity')\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "# List of identical segments\n",
    "for pair,segments in identical_dict.items():\n",
    "    print(pair)\n",
    "    for t in segments:\n",
    "        print(f\"{t[0]}: {segments_dict[t[0]]['text']}\")\n",
    "        print(f\"{t[1]}: {segments_dict[t[1]]['text']}\")\n",
    "        print()\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thematic Alignment\n",
    "\n",
    "### Method\n",
    "\n",
    "The method processes the matrix `topic_segment_matrix` contained in `model_dict`. This matrix contains the semantic similarities of all topic-segment pairs in our set of constitutions. \n",
    "\n",
    "For each constitution:\n",
    "\n",
    "- Get the topic-segment matrix contain only the constitution's segments.\n",
    "\n",
    "For each pair of constitutions the function `analyse_topic_alignment()`:\n",
    "\n",
    "- Obtain each constitution's topic profile from its topic-segment matrix using only the top scoring topics for each segment. The analysis here uses the top three topics.\n",
    "- Use vector similarity measures to compare the topic profiles of the constitutions. We use:\n",
    "    - Pearson's R correlation coefficient.\n",
    "    - Cosine similarity.\n",
    "\n",
    "### Visualisations\n",
    "\n",
    "Two visualisations are presented for two measures of topic profile comparison:\n",
    "\n",
    "- A heatmap showing topic profile correlation coefficients (Pearson's R) for every pair of constitutions.\n",
    "- A heatmap showing topic profile cosine similarities for every pair of constitutions.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get topic-segment matrix for each constitution\n",
    "topics_count = topic_segment_matrix.shape[0]\n",
    "topic_matrix_dict = {}\n",
    "for doc in doc_data:\n",
    "    segment_ids = [k for k,_ in segments_dict.items() if k.split('/')[0] == doc[0] and\\\n",
    "                             k in encoded]\n",
    "    segment_indices = [encoded.index(segment_id) for segment_id in segment_ids]\n",
    "    # Get the segments sub-matrix for the pair of documents\n",
    "    topic_matrix_dict[doc] = topic_segment_matrix[np.ix_(range(0,topics_count),segment_indices)]\n",
    "\n",
    "# Heatmap visualisations\n",
    "hm_corr_matrix = np.zeros((len(doc_data),len(doc_data)))\n",
    "hm_cos_matrix = np.zeros((len(doc_data),len(doc_data)))\n",
    "\n",
    "combs = combinations(doc_data,r=2)\n",
    "for c in combs:\n",
    "    m1 = topic_matrix_dict[c[0]]\n",
    "    m2 = topic_matrix_dict[c[1]]\n",
    "    # Get the alignment using the top k scoring topics for a segment k=3\n",
    "    results = analyse_topic_alignment(m1,m2,k=3)\n",
    "    hm_corr_matrix[doc_data.index(c[0]),doc_data.index(c[1])] = results['correlation']\n",
    "    hm_cos_matrix[doc_data.index(c[0]),doc_data.index(c[1])] = results['cosine']\n",
    "    \n",
    "plt.imshow(hm_corr_matrix,aspect='auto',cmap=mpl.cm.Blues)\n",
    "plt.yticks(range(0,len(const_list)),const_list)\n",
    "plt.xticks(range(0,len(const_list)),const_list,rotation=90)\n",
    "\n",
    "for (j,i),value in np.ndenumerate(hm_corr_matrix):\n",
    "    if round(value,2) > 0.3:\n",
    "        color = 'white'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    if value > 0:\n",
    "        plt.text(i,j,round(value,2),color=color,ha='center',va='center',alpha=0.9)\n",
    "plt.grid(alpha=0.6)\n",
    "plt.title('Heatmap of topic profile correlations')\n",
    "plt.show()\n",
    " \n",
    "print()\n",
    "\n",
    "plt.imshow(hm_cos_matrix,aspect='auto',cmap=mpl.cm.Blues)\n",
    "plt.yticks(range(0,len(const_list)),const_list)\n",
    "plt.xticks(range(0,len(const_list)),const_list,rotation=90)\n",
    "\n",
    "for (j,i),value in np.ndenumerate(hm_cos_matrix):\n",
    "    if round(value,2) > 0.3:\n",
    "        color = 'white'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    if value > 0:\n",
    "        plt.text(i,j,round(value,2),color=color,ha='center',va='center',alpha=0.9)\n",
    "plt.grid(alpha=0.6)\n",
    "plt.title('Heatmap of topic profile cosine similarities')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
